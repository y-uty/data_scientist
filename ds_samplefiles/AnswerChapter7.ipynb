{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 練習と総合問題解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下のライブラリを使うので、あらかじめ読み込んでおいてください\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# 可視化ライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# 小数第３位まで表示\n",
    "%precision 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <練習問題 7-1>\n",
    "\n",
    "3章で使った、数学の成績を示すデータである「student-mat.csv」を使って、学校を選んだ理由（`reason`）を円グラフ化して、それぞれの割合を出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 解答\n",
    "student_data_math = pd.read_csv('student-mat.csv',sep=';')\n",
    "student_data_math.groupby('reason').size().plot(kind='pie', autopct='%1.1f%%',startangle=90)\n",
    "plt.ylabel('')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <練習問題 7-2>\n",
    "\n",
    "<練習問題 7-2>と同じデータで、`higher` (高い教育を受けたいかどうか。値は`yes`か`no`）を軸にして、それぞれの数学の最終成績`G3`の平均値を棒グラフで表示してください。ここから何か推測できることはありますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答\n",
    "student_data_math.groupby('higher')['G3'].mean().plot(kind='bar')\n",
    "plt.xlabel('higher')\n",
    "plt.ylabel('G3 grade avg')\n",
    "\n",
    "# 高い教育を受けた人たちの方が成績は高めであることがわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <練習問題 7-3>\n",
    "\n",
    "<練習問題 7-2>と同じデータで、通学時間（`traveltime`）を軸にして、それぞれの数学の最終成績`G3`の平均値を横棒グラフで表示してください。何か推測できることはありますか？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答\n",
    "student_data_math.groupby(['traveltime'])['G3'].mean().plot(kind='barh')\n",
    "plt.xlabel('G3 Grade avg')\n",
    "\n",
    "# 通学時間が長いと成績が低くなる傾向にある"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 総合問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■総合問題7-1 時系列データ分析\n",
    "\n",
    "ここでは、本章で身に付けたpandasやscipyなどを使って、時系列データついて扱っていきましょう。\n",
    "\n",
    "（1）（データの取得と確認）下記のサイトより、dow_jones_index.zipをダウンロードし、含まれている`dow_jones_index.data`を使って、データを読み込み、はじめの5行を表示してください。またデータのそれぞれのカラム情報等を見て、`null`などがあるか確認してください。　　\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00312/dow_jones_index.zip　　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答 (1)\n",
    "# データの取得\n",
    "import requests, zipfile\n",
    "from io import StringIO\n",
    "import io\n",
    "\n",
    "# url \n",
    "zip_file_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00312/dow_jones_index.zip'\n",
    "r = requests.get(zip_file_url, stream=True)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "# 展開\n",
    "z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "dow_jones_index = pd.read_csv('dow_jones_index.data',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先頭5行の確認\n",
    "dow_jones_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのカラム情報\n",
    "dow_jones_index.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）（データの加工）カラムの`open`、`high`、`low`、`close`等のデータは数字の前に$マークが付いているため、これを取り除いてください。また、日時を`date`型で読み込んでいない場合は、date型に変換しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答 (2)\n",
    "# 型変更　日時型\n",
    "dow_jones_index.date = pd.to_datetime(dow_jones_index.date)\n",
    "\n",
    "# ＄マークを消す\n",
    "delete_dolchar = lambda x: str(x).replace('$', '')\n",
    "\n",
    "# 対象は、open,high,low.close,next_weeks_open,next_weeks_close\n",
    "# 文字型を数値型を変換する処理\n",
    "dow_jones_index.open = pd.to_numeric(dow_jones_index.open.map(delete_dolchar))\n",
    "dow_jones_index.high = pd.to_numeric(dow_jones_index.high.map(delete_dolchar))\n",
    "dow_jones_index.low = pd.to_numeric(dow_jones_index.low.map(delete_dolchar))\n",
    "dow_jones_index.close = pd.to_numeric(dow_jones_index.close.map(delete_dolchar))\n",
    "dow_jones_index.next_weeks_open = pd.to_numeric(dow_jones_index.next_weeks_open.map(delete_dolchar))\n",
    "dow_jones_index.next_weeks_close = pd.to_numeric(dow_jones_index.next_weeks_close.map(delete_dolchar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 再確認\n",
    "dow_jones_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）カラムの`close`について、各`stock`ごとの要約統計量を算出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答(3)\n",
    "# indexをセットする\n",
    "dow_jones_index_stock_index = dow_jones_index.set_index(['date','stock'])\n",
    "\n",
    "# データフレームワークの再構成\n",
    "dow_jones_index_stock_index_unstack = dow_jones_index_stock_index.unstack()\n",
    "\n",
    "# closeのみ対象\n",
    "dow_close_data = dow_jones_index_stock_index_unstack['close']\n",
    "\n",
    "#　要約統計量\n",
    "dow_close_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）カラムの`close`について、各`stock`の相関を算出する相関行列を出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答(4)\n",
    "# 相関行列\n",
    "corr_data = dow_close_data.corr()\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4 続き）また、`seaborn`の`heatmap`を使って、相関行列のヒートマップを描いてみましょう（ヒント：`pandas`の`corr()`を使います）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 解答(4)\n",
    "# ヒートマップ\n",
    "sns.heatmap(corr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5）(4)で算出した相関行列の中で一番相関係数が高い`stock`の組み合わせを抽出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答(5)\n",
    "# 相関係数が最大となるペアの抽出（自分自身以外の29ペアの中で）\n",
    "\n",
    "# initial value\n",
    "max_corr = 0\n",
    "stock_1 = ''\n",
    "stock_2 = ''\n",
    "\n",
    "for i in range(0,len(corr_data)):\n",
    "    print(\n",
    "        corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]].idxmax()[1],\n",
    "        corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]].idxmax()[0],\n",
    "        corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]][0]\n",
    "    )\n",
    "    if max_corr < corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]][0]:\n",
    "        max_corr = corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]][0]\n",
    "        stock_1 = corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]].idxmax()[1]\n",
    "        stock_2 = corr_data[i:i+1].unstack().sort_values(ascending=False)[[1]].idxmax()[0]\n",
    "\n",
    "# max_coorのペアを出力\n",
    "print('[Max Corr]:',max_corr)\n",
    "print('[stock_1]:',stock_1)\n",
    "print('[stock_2]:',stock_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5 続き）さらに、その中でもっとも相関係数が高いペアを抜き出し、それぞれの時系列グラフを描いてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答(5) グラフ化\n",
    "# ペアトレーディングなどに使われる。\n",
    "dow_close_data_subsets =dow_close_data[[stock_1,stock_2]]\n",
    "dow_close_data_subsets.plot(subplots=True,grid=True)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（6） pandasの`rolling()`（窓関数）を使って、上記で使った各`stock`ごとに、`close`の過去5期（5週間）移動平均時系列データを計算してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**[ポイント]**\n",
    ">\n",
    ">(6)、(7)の補足についての補足です。\n",
    ">\n",
    ">時系列データ$(\\cdots ,y_{t-1},y_t,y_{t+1}, \\cdots )$の過去n期の移動平均データとは、過去5期のデータの平均、つまり以下を意味します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "ma_t = \\sum_{s=t-n+1}^t \\frac{y_s}{n}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">時系列データ$(\\cdots ,y_{t-1},y_t,y_{t+1}, \\cdots )$の前期（1週前）との比の対数時系列データとは、$\\log \\frac{y_t} {y_{t-1}}$から成るデータのことです。増減率$r_t = \\frac{y_t - y_{t-1}}{y_t}$が小さいとき、$r_t \\approx \\log \\frac{y_t} {y_{t-1}}$の関係が成り立ちます。これは、$x$が十分小さいときに成り立つ、$\\log (1+x) \\approx x$から導かれます。増減率データ$(r_1,\\cdots ,r_N )$のボラティリティとは、標準偏差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "\\sqrt{\\frac{1}{N}\\sum_{t=1}^N (r_t - \\frac{1}{N}\\sum_{t=1}^N r_t)^2}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">のことで、価格変動の大きさを示す指標として利用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 解答(6)\n",
    "# 窓関数\n",
    "dow_close_data.rolling(center=False,window=5).mean().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（7） pandasの`shift()`を使って、上記で使った各stockごとに、`close`の前期（1週前）との比の対数時系列データを計算してください。さらに、この中で、一番ボラティリティ（標準偏差）が一番大きい`stock`と小さい`stock`を抜き出し、その対数変化率グラフを書いてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答(7)\n",
    "# 前週比（１期ずらし）をしたい場合、shiftを使う\n",
    "# loopなどを使うより、断然処理が速い\n",
    "log_ratio_stock_close = np.log(dow_close_data/dow_close_data.shift(1))\n",
    "\n",
    "max_vol_stock = log_ratio_stock_close.std().idxmax()\n",
    "min_vol_stock = log_ratio_stock_close.std().idxmin()\n",
    "\n",
    "# 最大と最小の標準偏差のstock\n",
    "print('max volatility:',max_vol_stock)\n",
    "print('min volatility:',min_vol_stock)\n",
    "\n",
    "#　グラフ化\n",
    "log_ratio_stock_close[max_vol_stock].plot()\n",
    "log_ratio_stock_close[min_vol_stock].plot()\n",
    "plt.ylabel('log ratio')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■総合問題7-2 マーケティング分析\n",
    "\n",
    "次は、マーケティング分析でよく扱われる購買データです。一般ユーザーとは異なる法人の購買データですが、分析する軸は基本的に同じです。\n",
    "\n",
    "（1）下記のURLで公開されているデータをpandasで読み込んでください（件数50万以上のデータで比較的大きいため、少し時間がかかります）。\n",
    "\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**[ヒント]**\n",
    ">\n",
    ">`pd.ExcelFile`を使って、シートを`.parse('Online Retail')`で指定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答 (1)\n",
    "#　時間がかかります\n",
    "file_url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'\n",
    "online_retail_data = pd.ExcelFile(file_url)\n",
    "\n",
    "# シートを指定する\n",
    "online_retail_data_table = online_retail_data.parse('Online Retail')\n",
    "online_retail_data_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの確認\n",
    "online_retail_data_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答 (1)\n",
    "# InvoiceNoの1文字目を抽出する処理。mapとLambda関数を使う\n",
    "online_retail_data_table['cancel_flg'] = online_retail_data_table.InvoiceNo.map(lambda x:str(x)[0])\n",
    "online_retail_data_table.groupby('cancel_flg').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、今回の分析対象は、`CustomerID`にデータが入っているレコードのみ対象にするため、そのための処理をしてください。さらに、カラムの`InvoiceNo`には数字の前に`C`があるものはキャンセルのため、このデータを取り除いてください。他にもデータとして取り除く必要なものがあれば、適宜処理してください。以下、このデータをベースに分析していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答　(1)\n",
    "# 「C」から始まるものはキャンセルデータなので、取り除く処理を書く\n",
    "# 「A」も異常値として処理して、削除する\n",
    "# 上記の結果から、今回は先頭が「5」であるものだけを分析対象とする\n",
    "# さらに、CustomerIDがあるデータだけを対象とする\n",
    "online_retail_data_table = online_retail_data_table[(online_retail_data_table.cancel_flg == '5') & (online_retail_data_table.CustomerID.notnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）このデータのカラムには、購買日時や商品名、数量、回数、購買者の`ID`などがあります。ここで、購買者（`CustomerID`）のユニーク数、バスケット数（`InvoiceNo`のユニーク数）、商品の種類（`StockCode`ベースと`Description`ベースのユニーク数）を求めてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答　(2)\n",
    "# unique ID\n",
    "print('購買者数（ユニーク）:',len(online_retail_data_table.CustomerID.unique()))\n",
    "\n",
    "# unique StockCode\n",
    "print('商品コード数:',len(online_retail_data_table.StockCode.unique()))\n",
    "\n",
    "# unique description\n",
    "# 上より多いから、同じstockcodeで違う名前になった商品がある。\n",
    "print('商品名の種類数:',len(online_retail_data_table.Description.unique()))\n",
    "\n",
    "# unique bascket\n",
    "print('バスケット数:',len(online_retail_data_table.InvoiceNo.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）このデータのカラムには、`Country`があります。このカラムを軸に、それぞれの国の購買合計金額（単位あたりの金額×数量の合計）を求め、降順にならべて、上位5つの国の結果を表示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答 (3)\n",
    "# 売り上げ合計を求めるため、新しいカラムの追加（売り上げ＝数量×単価）\n",
    "online_retail_data_table['TotalPrice'] = online_retail_data_table.Quantity * online_retail_data_table.UnitPrice\n",
    "\n",
    "#　それぞれの国ごとに売り上げ合計金額を算出\n",
    "country_data_total_p = online_retail_data_table.groupby('Country')['TotalPrice'].sum()\n",
    "\n",
    "# 値に対して、降順にソートして、TOP5を抜き出す。\n",
    "top_five_country =country_data_total_p.sort_values(ascending=False)[0:5]\n",
    "\n",
    "# TOP5の国\n",
    "print(top_five_country)\n",
    "\n",
    "# TOP5の国のリスト\n",
    "print('TOP5の国のリスト:',top_five_country.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）上の上位5つの国について、それぞれの国の商品売り上げ（合計金額）の月別の時系列推移をグラフにしてください。ここで、グラフは分けて表示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解答 (4)\n",
    "# TOP5だけのデータを作成。\n",
    "top_five_country_data = online_retail_data_table[online_retail_data_table['Country'].isin(top_five_country.index)]\n",
    "\n",
    "# date と国ごとの売り上げ\n",
    "top_five_country_data_country_totalP =top_five_country_data.groupby(['InvoiceDate','Country'],as_index=False)['TotalPrice'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 解答 (4)\n",
    "# TOP 5の売り上げ月別推移\n",
    "\n",
    "# indexの設定（日時と国）\n",
    "top_five_country_data_country_totalP_index=top_five_country_data_country_totalP.set_index(['InvoiceDate','Country'])\n",
    "\n",
    "# 再構成\n",
    "top_five_country_data_country_totalP_index_uns = top_five_country_data_country_totalP_index.unstack()\n",
    "\n",
    "# resampleで時系列のデータを月別や四半期等に変更できる。今回は、月別(M)の合計を算出。そのあと、グラフ化\n",
    "top_five_country_data_country_totalP_index_uns.resample('M').sum().plot(subplots=True,figsize=(12,10))\n",
    "\n",
    "# グラフが被らないように\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5）上の上位5つの国について、それぞれの国における商品の売り上げトップ5の商品を抽出してください。また、それらを国ごとに円グラフにしてください。なお、商品は「`Description`」ベースで集計してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 解答 (5)\n",
    "for x in top_five_country.index:\n",
    "    #print('Country:',x)\n",
    "    country = online_retail_data_table[online_retail_data_table['Country'] == x]\n",
    "    country_stock_data = country.groupby('Description')['TotalPrice'].sum()\n",
    "    top_five_country_stock_data=pd.DataFrame(country_stock_data.sort_values(ascending=False)[0:5])    \n",
    "    plt.figure()\n",
    "    plt.pie(\n",
    "        top_five_country_stock_data,\n",
    "        labels=top_five_country_stock_data.index,\n",
    "        counterclock=False,\n",
    "        startangle=90,\n",
    "        autopct='%.1f%%',\n",
    "        pctdistance=0.7\n",
    "    )\n",
    "    plt.ylabel(x)\n",
    "    plt.axis('equal')\n",
    "    #print(top_five_country_stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※補足：他、余力がある方は以下の課題に取り組んでみてください。なお、大学の講座等の課題に使っているため解答は省略しますので、あらかじめご了承ください。\n",
    "\n",
    "追加課題：購買者（CustomerID）の各合計購買金額を算出し、さらに金額をベースに降順に並び替えをします。カラムがCustomerIDと合計金額のあるテーブルを作成してください。そこから、購買者を10等分にグループ分けします（例：100人いたら、10人ずつにグループ分けします。）。それぞれのグループでの合計購買金額の範囲と、それぞれの金額合計値を算出してください（このアプローチを**デシル分析**といいます。）。この結果を用いて、パレートの法則（上位2割の顧客が売上全体の8割を占める）を確かめるため、それぞれのグループが売上の何割を占めるか計算してください。なお、マーケティング戦略では、このように顧客を分けることを**セグメンテーション**といい、上位2割に絞ってアプローチを仕掛けることを**ターゲティング**といいます。それぞれの戦略によりますが、優良顧客に的を絞った方が投資対効果が高いことが多いため、このようなアプローチを取ることがあります。\n",
    "\n",
    "ヒントは、6章で学んだビン分割などを使います。"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
